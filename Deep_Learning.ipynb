{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2859fb16",
   "metadata": {},
   "source": [
    "# Deep Q Learning\n",
    "\n",
    "#### Can I take the findings from Q-Learning, and extend it to a deep learning framework?\n",
    "\n",
    "#### Use this framework to incorporate Card Count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b56034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason, importing this first doesn't crash the kernel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263e4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Custom Modules.\n",
    "from Game import Game\n",
    "from Player import Player\n",
    "\n",
    "# Custom Functions.\n",
    "from RecursePlayer import recursePlayer,dealHouse,getReward,getValue\n",
    "from Q_Learning import initQ,learnPolicy,evaluatePolicy,getBestAction\n",
    "from Utils import dfBestMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7c5771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c00b1",
   "metadata": {},
   "source": [
    "### Import learned Q function to be used for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fe7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qlearned = np.load('Q.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f66c9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackjack = Game(Player)\n",
    "cardMap = blackjack.cardMap\n",
    "cardValues = blackjack.cardValues\n",
    "allCards = list(cardMap.values())\n",
    "\n",
    "card_comb_all = []\n",
    "card_comb = [[c1,c2] for i,c1 in enumerate(allCards) for c2 in allCards[i:]]\n",
    "all_comb = [[c1,c2] for c1 in allCards for c2 in allCards]\n",
    "for c in card_comb :\n",
    "    for a in all_comb :\n",
    "        card_comb_all.append([[c]]+[a])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2c576",
   "metadata": {},
   "source": [
    "### Observe distribution of Card Count in several games played.\n",
    "\n",
    "The module automatically handles reshuffling, so I can just repeat play without re-initializing the module.\n",
    "\n",
    "I have a \"ratio penetrate\" flag, which defaults to 4/6 . This means that the deck is reshuffled after it gets through 4/6'ths of the deck. I default to 6 deck game as well. You can adjust these values in the Game module.\n",
    "\n",
    "The distribution of count will be dependent on number of decks used, and ratio penetrate. Although with large ratio penetrate, the distribution might seem a bit misleading. This is because, if there is a large/small count at the point of reshuffling, we neglect the fact that if we play every card (instead of stopping short to reshuffle), the count will converge back to 0 by the end of the deck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e1e725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackjack = Game(Player,verbose=False)\n",
    "\n",
    "blackjack.initRound(wagers=[1])\n",
    "blackjack.dealInit()\n",
    "\n",
    "blackjack.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25cf960e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['A', 'Q']], [[9, 'A']])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackjack.players[0].cards , blackjack.house.cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff522263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "blackjack = Game(Player,verbose=False)\n",
    "count = []\n",
    "\n",
    "for _ in range(50000) :\n",
    "    \n",
    "    count.append(blackjack.count)\n",
    "    \n",
    "    blackjack.initRound(wagers=[1])\n",
    "    blackjack.dealInit()\n",
    "    player = blackjack.players[0] # only 1 player, so i'll just extract that specific player module.\n",
    "    houseShow = blackjack.getHouseShow(showValue=True)\n",
    "\n",
    "    while not player.isDone() :\n",
    "\n",
    "        playerShow,canSplit,useableAce,card1 = player.getValue()\n",
    "\n",
    "        policy = player.getValidMoves(houseShow)\n",
    "        policy = [p for p in policy if p!='insurance']\n",
    "        if canSplit :\n",
    "            move = getBestAction(Qlearned['canSplit'][(card1,houseShow,useableAce)],policy,-1,False)\n",
    "        else :\n",
    "            move = getBestAction(Qlearned['noSplit'][(playerShow,houseShow,useableAce)],policy,-1,False)\n",
    "\n",
    "        # Gather count after every single move.\n",
    "        count.append(blackjack.count)\n",
    "\n",
    "        blackjack.stepPlayer(player,move)\n",
    "    blackjack.stepHouse()\n",
    "    \n",
    "plt.figure(figsize=(15,4))\n",
    "inds = np.argsort(pd.Series(count).value_counts(normalize=True).index.to_list())\n",
    "plt.bar(\n",
    "    pd.Series(count).value_counts(normalize=True).index[inds],\n",
    "    pd.Series(count).value_counts(normalize=True).values[inds]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0b7ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1     8185\n",
       " 1     8173\n",
       " 0     8066\n",
       "-2     7750\n",
       " 2     7311\n",
       "-3     7014\n",
       " 3     6574\n",
       "-4     6047\n",
       " 4     6010\n",
       "-5     5253\n",
       " 5     5214\n",
       " 6     4606\n",
       "-6     4430\n",
       " 7     3911\n",
       "-7     3670\n",
       " 8     3256\n",
       "-8     3087\n",
       " 9     2676\n",
       "-9     2544\n",
       " 10    2278\n",
       "-10    2106\n",
       " 11    1950\n",
       "-11    1669\n",
       " 12    1482\n",
       "-12    1250\n",
       " 13    1164\n",
       "-13     978\n",
       " 14     965\n",
       "-14     750\n",
       " 15     702\n",
       "-15     538\n",
       " 16     527\n",
       " 17     368\n",
       "-16     359\n",
       "-17     265\n",
       " 18     231\n",
       "-18     211\n",
       " 19     200\n",
       "-19     143\n",
       " 20     131\n",
       " 21     126\n",
       "-20     126\n",
       "-21      86\n",
       " 22      69\n",
       "-22      53\n",
       " 23      32\n",
       "-23      32\n",
       " 24      20\n",
       " 25      19\n",
       "-24      16\n",
       " 26      10\n",
       "-25      10\n",
       " 27       5\n",
       " 28       3\n",
       "-26       3\n",
       " 29       2\n",
       " 32       2\n",
       " 31       2\n",
       " 30       1\n",
       "-27       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(count).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14ccb7",
   "metadata": {},
   "source": [
    "## Deep Q Learning\n",
    "\n",
    "\n",
    "The Q learning without card count is found in my previous notebook. While we determine the Q function explicitly, this requires access to all state-action pairs.\n",
    "\n",
    "In Deep Q Learning, we are ultimately approximating the Q function through use of linear + non-linear layers in a neural network, attempting to minimize MSE between predicted and actual Q values. We will ultimately be regressing the Q value for each possible action for a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90dfa2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module) :\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_layers=[]) :\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        assert len(hidden_layers) , \"must have at least 1 hidden layer\"\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.fc_input = nn.Linear(self.input_dim, self.hidden_layers[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc_hidden = []\n",
    "        for i in range(len(self.hidden_layers)-1) :\n",
    "            self.fc_hidden.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "            \n",
    "        self.fc_output = nn.Linear(self.hidden_layers[-1], self.output_dim)\n",
    "        \n",
    "    def forward(self, data) :\n",
    "        \n",
    "        x = self.relu(self.fc_input(data))\n",
    "        \n",
    "        for layer in self.fc_hidden :\n",
    "            x = self.relu(layer(x))\n",
    "        \n",
    "        return self.fc_output(x)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22809a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module) :\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden1, hidden2) :\n",
    "        super(Net, self).__init__()\n",
    "                \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.output_dim = output_dim\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_input = nn.Linear(self.input_dim, self.hidden1)\n",
    "        self.fc_hidden = nn.Linear(self.hidden1, self.hidden2)\n",
    "        self.fc_output = nn.Linear(self.hidden2, self.output_dim)\n",
    "        \n",
    "    def forward(self, data) :\n",
    "        \n",
    "        x = self.relu(self.fc_input(data))\n",
    "        x = self.relu(self.fc_hidden(x))\n",
    "        \n",
    "        \n",
    "        return self.fc_output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff94f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(2,5,[10,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924b3260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1933,  0.0222, -0.3071,  0.3606, -0.2790], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(torch.Tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ce26db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0443d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
