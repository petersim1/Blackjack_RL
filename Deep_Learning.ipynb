{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2859fb16",
   "metadata": {},
   "source": [
    "# Deep Q Learning\n",
    "\n",
    "#### Can I take the findings from Q-Learning, and extend it to a deep learning framework?\n",
    "\n",
    "#### Use this framework to incorporate Card Count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b56034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason, importing this first doesn't crash the kernel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263e4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Custom Modules.\n",
    "from Game import Game\n",
    "from Player import Player\n",
    "\n",
    "# Custom Functions.\n",
    "from RecursePlayer import recursePlayer,dealHouse,getReward,getValue\n",
    "from Q_Learning import initQ,learnPolicy,evaluatePolicy,getBestAction\n",
    "from Utils import dfBestMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7c5771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c00b1",
   "metadata": {},
   "source": [
    "### Import learned Q function to be used for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fe7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qlearned = np.load('Q.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f66c9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackjack = Game(Player)\n",
    "cardMap = blackjack.cardMap\n",
    "cardValues = blackjack.cardValues\n",
    "allCards = list(cardMap.values())\n",
    "\n",
    "card_comb_all = []\n",
    "card_comb = [[c1,c2] for i,c1 in enumerate(allCards) for c2 in allCards[i:]]\n",
    "all_comb = [[c1,c2] for c1 in allCards for c2 in allCards]\n",
    "for c in card_comb :\n",
    "    for a in all_comb :\n",
    "        card_comb_all.append([[c]]+[a])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2c576",
   "metadata": {},
   "source": [
    "### Observe distribution of Card Count in several games played.\n",
    "\n",
    "The module automatically handles reshuffling, so I can just repeat play without re-initializing the module.\n",
    "\n",
    "I have a \"ratio penetrate\" flag, which defaults to 4/6 . This means that the deck is reshuffled after it gets through 4/6'ths of the deck. I default to 6 deck game as well. You can adjust these values in the Game module.\n",
    "\n",
    "The distribution of count will be dependent on number of decks used, and ratio penetrate. Although with large ratio penetrate, the distribution might seem a bit misleading. This is because, if there is a large/small count at the point of reshuffling, we neglect the fact that if we play every card (instead of stopping short to reshuffle), the count will converge back to 0 by the end of the deck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff522263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "blackjack = Game(Player,verbose=False)\n",
    "count = []\n",
    "\n",
    "for _ in range(50000) :\n",
    "    \n",
    "    count.append(blackjack.count)\n",
    "    \n",
    "    blackjack.initRound(wagers=[1])\n",
    "    blackjack.dealInit()\n",
    "    player = blackjack.players[0] # only 1 player, so i'll just extract that specific player module.\n",
    "    houseShow = blackjack.getHouseShow(showValue=True)\n",
    "\n",
    "    while not player.isDone() :\n",
    "\n",
    "        playerShow,canSplit,useableAce,card1 = player.getValue()\n",
    "\n",
    "        policy = player.getValidMoves(houseShow)\n",
    "        policy = [p for p in policy if p!='insurance']\n",
    "        if canSplit :\n",
    "            move = getBestAction(Qlearned['canSplit'][(card1,houseShow,useableAce)],policy,-1,False)\n",
    "        else :\n",
    "            move = getBestAction(Qlearned['noSplit'][(playerShow,houseShow,useableAce)],policy,-1,False)\n",
    "\n",
    "        count.append(blackjack.count)\n",
    "\n",
    "        blackjack.stepPlayer(player,move)\n",
    "    blackjack.stepHouse()\n",
    "    \n",
    "plt.figure(figsize=(15,4))\n",
    "inds = np.argsort(pd.Series(count).value_counts(normalize=True).index.to_list())\n",
    "plt.bar(\n",
    "    pd.Series(count).value_counts(normalize=True).index[inds],\n",
    "    pd.Series(count).value_counts(normalize=True).values[inds]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14ccb7",
   "metadata": {},
   "source": [
    "## Deep Q Learning\n",
    "\n",
    "\n",
    "The Q learning without card count is found in my previous notebook. While we determine the Q function explicitly, this requires access to all state-action pairs.\n",
    "\n",
    "In Deep Q Learning, we are ultimately approximating the Q function through use of linear + non-linear layers in a neural network, attempting to minimize MSE between predicted and actual Q values. We will ultimately be regressing the Q value for each possible action for a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90dfa2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module) :\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_layers=[]) :\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        assert len(hidden_layers) , \"must have at least 1 hidden layer\"\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.fc_input = nn.Linear(self.input_dim, self.hidden_layers[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc_hidden = []\n",
    "        for i in range(len(self.hidden_layers)-1) :\n",
    "            self.fc_hidden.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "            \n",
    "        self.fc_output = nn.Linear(self.hidden_layers[-1], self.output_dim)\n",
    "        \n",
    "    def forward(self, data) :\n",
    "        \n",
    "        x = self.relu(self.fc_input(data))\n",
    "        \n",
    "        for layer in self.fc_hidden :\n",
    "            x = self.relu(layer(x))\n",
    "        \n",
    "        return self.fc_output(x)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22809a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module) :\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden1, hidden2) :\n",
    "        super(Net, self).__init__()\n",
    "                \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.output_dim = output_dim\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_input = nn.Linear(self.input_dim, self.hidden1)\n",
    "        self.fc_hidden = nn.Linear(self.hidden1, self.hidden2)\n",
    "        self.fc_output = nn.Linear(self.hidden2, self.output_dim)\n",
    "        \n",
    "    def forward(self, data) :\n",
    "        \n",
    "        x = self.relu(self.fc_input(data))\n",
    "        x = self.relu(self.fc_hidden(x))\n",
    "        \n",
    "        \n",
    "        return self.fc_output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff94f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(2,5,[10,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924b3260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1933,  0.0222, -0.3071,  0.3606, -0.2790], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(torch.Tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ce26db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0443d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
